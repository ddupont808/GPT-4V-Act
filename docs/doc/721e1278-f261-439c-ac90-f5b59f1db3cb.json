{
    "summary": "This code initializes modules, sets up a chat controller, defines actions, and handles various input events, including screenshots, data export, window resizing, and label exporting, while also handling unknown actions by logging messages.",
    "details": [
        {
            "comment": "This code initializes necessary modules, sets up an OpenAI chat controller, and defines various action types for user interactions. It also provides a response format with a brief explanation and the next action to be performed.",
            "location": "\"/media/root/Toshiba XG3/works/GPT-4V-Act/docs/src/main.js\":0-30",
            "content": "const { app, BrowserWindow, ipcMain, webContents } = require('electron')\nconst { promisify } = require('util');\nconst path = require('node:path')\nconst fs = require('fs/promises');\nconst sleep = promisify(setTimeout);\nconst OpenAIChatController = require('./chatgpt');\nlet win;\nconst controller = new OpenAIChatController();\nconst prompt = (task, info) => `task: ${task}\ntype ClickAction = { action: \"click\", element: number }\ntype TypeAction = { action: \"type\", element: number, text: string }\ntype ScrollAction = { action: \"scroll\", direction: \"up\" | \"down\" }\ntype RequestInfoFromUser = { action: \"request-info\", prompt: string }\ntype RememberInfoFromSite = { action: \"remember-info\", info: string }\ntype Done = { action: \"done\" }\n## response format\n{\n  briefExplanation: string,\n  nextAction: ClickAction | TypeAction | ScrollAction | RequestInfoFromUser | RememberInfoFromSite | Done\n}\n## response examples\n{\n  \"briefExplanation\": \"I'll type 'funny cat videos' into the search bar\"\n  \"nextAction\": { \"action\": \"type\", \"element\": 11, \"text\": \"funny cat videos\" }"
        },
        {
            "comment": "This code is parsing JSON blocks from Markdown content. It first defines a regular expression to match the JSON block, then uses it to extract the JSON content from the provided Markdown string. If a valid JSON block is found, it trims and parses the extracted JSON, returning it if successful. Otherwise, it returns null or logs an error message for failed parsing.",
            "location": "\"/media/root/Toshiba XG3/works/GPT-4V-Act/docs/src/main.js\":31-64",
            "content": "}\n{\n  \"briefExplanation\": \"Today's doodle looks interesting, I'll click it\"\n  \"nextAction\": { \"action\": \"click\", \"element\": 9 }\n}\n{\n  \"briefExplanation\": \"I have to login to create a post\"\n  \"nextAction\": { \"action\": \"request-info\", \"prompt\": \"What is your login information?\" }\n}\n{\n  \"briefExplanation\": \"Today's doodle is about Henrietta Lacks, I'll remember that for our blog post\"\n  \"nextAction\": { \"action\": \"remember-info\", \"info\": \"Today's doodle is about Henrietta Lacks\" }\n}\n## stored info\n${JSON.stringify(info)}\n## instructions\n# observe the screenshot, and think about the next action\n# output your response in a json markdown code block\n`;\nfunction extractJsonFromMarkdown(mdString) {\n  const regex = /```json\\s*([\\s\\S]+?)\\s*```/; // This captures content between ```json and ```\n  const match = mdString.match(regex);\n  if (!match) return null;  // No JSON block found\n  const jsonString = match[1].trim();\n  try {\n      return JSON.parse(jsonString);\n  } catch (err) {\n      console.error('Failed to parse JSON:', err);"
        },
        {
            "comment": "The code is responsible for creating a new BrowserWindow, handling events related to the webview, and taking a screenshot. It also includes checks for invalid JSON content and sets various window properties like width, height, and title bar style.",
            "location": "\"/media/root/Toshiba XG3/works/GPT-4V-Act/docs/src/main.js\":65-114",
            "content": "      return null;  // Invalid JSON content\n  }\n}\nfunction createWindow() {\n  win = new BrowserWindow({\n    width: 1280,\n    height: 720,\n    titleBarStyle: 'hidden',\n    titleBarOverlay: {\n      color: '#18181b',\n      symbolColor: '#74b1be'\n    },\n    webPreferences: {\n      preload: path.join(__dirname, 'preload.js'),\n      webviewTag: true,\n      contextIsolation: false\n    }\n  })\n  ipcMain.on('current-url', (event, url) => {\n    win.webContents.send('update-url', url);\n  });\n  win.loadFile('index.html')\n}\napp.whenReady().then(async () => {\n  createWindow();\n  app.on('activate', () => {\n    if (BrowserWindow.getAllWindows().length === 0) {\n      createWindow()\n    }\n  });\n  let webview;\n  let labelData;\n  ipcMain.on('webview-ready', async (event, id) => {\n    webview = webContents.fromId(id);\n    console.log(`Acquired webviewId ${id}`);\n  });\n  ipcMain.on('label-data', (event, data) => {\n    labelData = JSON.parse(data);\n  });\n  async function screenshot() {\n    webview.send('observer', 'screenshot-start');\n    await sleep(100);"
        },
        {
            "comment": "Taking a screenshot and saving it with a timestamp, creating a unique filename.\nSending 'screenshot-start' message to observer and waiting for 200ms.\nReading label data from the file '_annotations.coco.json'.\nCreating new image IDs and annotations IDs based on current maximum values.\nLooping through saved label data, creating annotations, and saving them in the 'dataset/_annotations.coco.json' file.",
            "location": "\"/media/root/Toshiba XG3/works/GPT-4V-Act/docs/src/main.js\":115-142",
            "content": "    const image = await webview.capturePage();\n    webview.send('observer', 'screenshot-end');\n    await fs.writeFile('tmp/screenshot.png', image.toPNG());\n    await controller.uploadImage('tmp/screenshot.png');\n  }\n  async function exportLabel() {\n    webview.send('observer', 'screenshot-start');\n    await sleep(200);\n    const savedData = labelData;\n    webview.send('observer', 'screenshot-end');\n    await sleep(200);\n    const image = await webview.capturePage();\n    // Create unique filename\n    const timestamp = Date.now();\n    const screenshotFilename = `screenshot_${timestamp}.png`;\n    const {width, height} = image.getSize();\n    // Save the image with unique name\n    await fs.writeFile(`dataset/${screenshotFilename}`, image.toPNG());\n    let coco = JSON.parse(await fs.readFile('dataset/_annotations.coco.json'));\n    const image_id = Math.max(...coco.images.map(({ id }) => id), 0) + 1;\n    const annotations_id = Math.max(...coco.annotations.map(({ id }) => id), 0) + 1;\n    let annotations = savedData.reduce((all, { bboxs }, index) => {"
        },
        {
            "comment": "This code is creating a new COCO annotations JSON file for a dataset of images. It takes screenshots and creates bounding box annotations for objects within each image, then updates the COCO format for labeling. The code also provides functions to capture screenshots, export the annotated data, and randomize image sizes.",
            "location": "\"/media/root/Toshiba XG3/works/GPT-4V-Act/docs/src/main.js\":143-179",
            "content": "      let bbox_annotations = bboxs.map((bbox, bboxIndex) => {\n        return {\n          id: index + annotations_id + bboxIndex, \n          image_id,\n          category_id: 0,\n          bbox, \n          area: bbox[2] * bbox[3],\n          segmentation: [],\n          iscrowd: 0\n        }\n      });\n      return all.concat(bbox_annotations);\n    }, []);\n    coco.annotations = coco.annotations.concat(annotations);\n    // update coco image format for labeling\n    let cocoImageFormat = { \n      id: image_id,\n      width,\n      height,\n      file_name: screenshotFilename, // updated filename\n      license: 1, \n      date_captured: new Date()\n    };\n    coco.images.push(cocoImageFormat);\n    await fs.writeFile('dataset/_annotations.coco.json', JSON.stringify(coco, null, 2));\n  }\n  ipcMain.on('screenshot', async (event, id) => screenshot());\n  ipcMain.on('export', async (event, id) => exportLabel());\n  ipcMain.on('randomize', async (event, id) => {\n    function randomizeSize() {\n      const [minWidth, minHeight] = [1280, 720];"
        },
        {
            "comment": "This code resizes the window and updates its position while loading different URLs from a dataset.",
            "location": "\"/media/root/Toshiba XG3/works/GPT-4V-Act/docs/src/main.js\":180-206",
            "content": "      const [maxWidth, maxHeight] = [3440, 1440];\n      // Get the old window size and position\n      const [oldWidth, oldHeight] = win.getSize();\n      const [oldX, oldY] = win.getPosition();\n      // Generate new random size\n      const width = Math.floor(Math.random() * (maxWidth - minWidth + 1) + minWidth);\n      const height = Math.floor(Math.random() * (maxHeight - minHeight + 1) + minHeight);\n      // Compute new position to keep bottom-right corner in the same position\n      const x = oldX + (oldWidth - width);\n      const y = oldY + (oldHeight - height);\n      // Set new size and position\n      win.setSize(width, height, false);\n      win.setPosition(x, y, false);\n    }\n    const urls = JSON.parse(await fs.readFile('dataset/urls.json'));\n    for(let i = 0; i < 10; i++) {\n      webview.send('navigate-webview', 'loadURL', urls.shuffles[parseInt(Math.random() * urls.shuffles.length)]);\n      await sleep(5000);\n      for(let i = 0; i < 10; i++) {\n        randomizeSize();\n        await sleep(100);\n        webview.send('shuffle');"
        },
        {
            "comment": "1. Waits 1500 milliseconds and exports label.\n2. Navigates webview to a random URL every 5 seconds for 10 times.\n3. Randomizes the size of the webview every 100 milliseconds for 10 times.\n4. Exports the label after each iteration of navigation and size randomization.\n5. Listens for 'send' event, saves current task text, takes a screenshot, types the text into prompt, and clicks send button.\n6. Listens for 'continue' event, takes a screenshot, types previous current task text into prompt, and clicks send button.\n7. Defines an action function to be executed when 'execute' event is triggered with a text parameter.\n8. On 'end_turn' event, checks if there are any open BrowserWindow instances, and if so, extracts JSON data from Markdown content.",
            "location": "\"/media/root/Toshiba XG3/works/GPT-4V-Act/docs/src/main.js\":207-248",
            "content": "        await sleep(1500);\n        await exportLabel();\n      }\n    }\n    for(let i = 0; i < 10; i++) {\n      webview.send('navigate-webview', 'loadURL', urls.random[parseInt(Math.random() * urls.random.length)]);\n      await sleep(5000);\n      for(let i = 0; i < 10; i++) {\n        randomizeSize();\n        await sleep(100);\n        webview.send('randomize');\n        await sleep(1500);\n        await exportLabel();\n      }\n    }\n  });\n  let currentTask;\n  ipcMain.on('send', async (event, text) => {\n    currentTask = text;\n    await screenshot();\n    await controller.typeIntoPrompt(prompt(text, []));\n    await controller.clickSendButton();\n  });\n  ipcMain.on('continue', async (event, text) => {\n    await screenshot();\n    await controller.typeIntoPrompt(prompt(currentTask, []));\n    await controller.clickSendButton();\n  });\n  let action = () => {};\n  ipcMain.on('execute', async (event, text) => {\n    action();\n  });\n  controller.on('end_turn', (content) => {\n    if (BrowserWindow.getAllWindows().length === 0) return;\n    const data = extractJsonFromMarkdown(content);"
        },
        {
            "comment": "Sends the end_turn message with a corresponding content, then defines an action function for handling the nextAction. If data is not null, it performs a switch case based on the nextAction's action type (click or type). It logs and executes the respective action on the webview.",
            "location": "\"/media/root/Toshiba XG3/works/GPT-4V-Act/docs/src/main.js\":249-276",
            "content": "    let msg = data === null ? content : data.briefExplanation;\n    win.webContents.send('end_turn', msg);\n    action = () => {\n      if(data != null) {\n        switch(data.nextAction.action) {\n          case \"click\":\n              console.log(`clicking ${JSON.stringify(labelData[data.nextAction.element])}`);\n              let { x, y } = labelData[data.nextAction.element];\n              webview.sendInputEvent({\n                type: 'mouseDown', \n                x, y,\n                clickCount: 1\n              });\n              webview.sendInputEvent({\n                type: 'mouseUp', \n                x, y,\n                clickCount: 1\n              });\n              break;\n          case \"type\": {\n              console.log(`typing ${data.nextAction.text} into ${JSON.stringify(labelData[data.nextAction.element])}`);\n              let { x, y } = labelData[data.nextAction.element];\n              webview.sendInputEvent({\n                type: 'mouseDown', \n                x, y,\n                clickCount: 1\n              });"
        },
        {
            "comment": "This code handles various types of mouse and keyboard input events by sending them to the webview, and also initializes the controller for the application. If an unknown action is encountered, it logs a message.",
            "location": "\"/media/root/Toshiba XG3/works/GPT-4V-Act/docs/src/main.js\":277-307",
            "content": "              webview.sendInputEvent({\n                type: 'mouseUp', \n                x, y,\n                clickCount: 1\n              });\n              for(let char of data.nextAction.text) {\n                webview.sendInputEvent({\n                  type: 'char', \n                  keyCode: char\n                });\n              }\n              break;\n            }\n          default:\n            console.log(`unknown action ${JSON.stringify(data.nextAction)}`);\n            break;\n        }\n      }\n    };\n  });\n  await controller.initialize();\n})\napp.on('window-all-closed', () => {\n  if (process.platform !== 'darwin') {\n    app.quit()\n  }\n})"
        }
    ]
}